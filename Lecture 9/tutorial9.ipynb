{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#The youtube series that I followed: https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4, Github for the codes: https://github.com/patrickloeber/pytorchTutorial/blob/master/01_Installation\n",
        "#LSTM Theory: https://www.youtube.com/watch?v=YCzL96nL7j0\n",
        "#Codes for LSTM: https://www.youtube.com/watch?v=AvKSPZ7oyVg\n",
        "#PyTorch package codes: https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/linear.py"
      ],
      "metadata": {
        "id": "Wj2NxeDtO-A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxzDExNGibBF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor Basics"
      ],
      "metadata": {
        "id": "WWaFz_66Chz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.empty(1)\n",
        "print(x1)\n",
        "\n",
        "x2 = torch.empty(3)\n",
        "print(x2)\n",
        "\n",
        "x3 = torch.empty(2, 3)\n",
        "print(x3)\n",
        "\n",
        "x4 = torch.empty(2, 2, 3)\n",
        "print(x4)\n",
        "\n",
        "x5 = torch.empty(2, 2, 2, 3)\n",
        "print(x5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-d9XKcwjS8g",
        "outputId": "884a3a3c-6492-4c31-b5ef-a7ab14300ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.2166e-32])\n",
            "tensor([1.9369e-32, 0.0000e+00, 4.6356e+11])\n",
            "tensor([[2.8966e-32, 0.0000e+00, 3.6631e-32],\n",
            "        [0.0000e+00, 1.1210e-43, 0.0000e+00]])\n",
            "tensor([[[3.4416e+05, 4.4460e-41, 1.5081e-38],\n",
            "         [0.0000e+00, 6.6017e+03, 4.4460e-41]],\n",
            "\n",
            "        [[1.3738e-38, 0.0000e+00, 1.5080e-38],\n",
            "         [0.0000e+00, 6.6018e+03, 4.4460e-41]]])\n",
            "tensor([[[[1.3834e-38, 0.0000e+00, 1.3884e-38],\n",
            "          [0.0000e+00, 1.5099e-38, 0.0000e+00]],\n",
            "\n",
            "         [[1.5117e-38, 0.0000e+00, 1.3834e-38],\n",
            "          [0.0000e+00, 1.5077e-38, 0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[3.9149e+04, 4.4460e-41, 3.9137e+04],\n",
            "          [4.4460e-41, 1.5099e-38, 0.0000e+00]],\n",
            "\n",
            "         [[1.5077e-38, 0.0000e+00, 1.5099e-38],\n",
            "          [0.0000e+00, 1.5077e-38, 0.0000e+00]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x6 = torch.rand(2,2)\n",
        "print(x6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D6SdesOjYbC",
        "outputId": "7f48637d-ca51-4969-c2f9-3d3b8107ac56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0508, 0.2936],\n",
            "        [0.6220, 0.3142]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x7 = torch.ones(2,2, dtype=torch.int)\n",
        "print(x7)\n",
        "print(x7.dtype)\n",
        "\n",
        "x8 = torch.ones(2,2, dtype=torch.float64)\n",
        "print(x8)\n",
        "print(x8.dtype)\n",
        "\n",
        "x9 = torch.ones(2,2, dtype=torch.float16)\n",
        "print(x9)\n",
        "print(x9.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7rB_47wkKy7",
        "outputId": "bc493c91-4858-45d6-f3a9-779d0333f88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1],\n",
            "        [1, 1]], dtype=torch.int32)\n",
            "torch.int32\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float64)\n",
            "torch.float64\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x10 = torch.tensor([[2.5, 0.1],[-1.0, 2.5]])\n",
        "print(x10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8e2aXJ1vL2d",
        "outputId": "0e0bae71-d7bc-4823-eb0c-801770673f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.5000,  0.1000],\n",
            "        [-1.0000,  2.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = torch.ones(2,2)\n",
        "y1.add_(x7)\n",
        "print(y1)\n",
        "\n",
        "y2 = torch.ones(2,2)\n",
        "y2.sub_(x7)\n",
        "print(y2)\n",
        "\n",
        "y3 = torch.sub(y2,x7)\n",
        "print(y3)\n",
        "\n",
        "y4 = torch.mul(y1,x10)\n",
        "print(y4)\n",
        "\n",
        "y5 = torch.div(y1,x10)\n",
        "print(y5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7QqLMYHpKQ5",
        "outputId": "bb1ea7dd-5b59-4c2f-f322-9d5840ec7740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[-1., -1.],\n",
            "        [-1., -1.]])\n",
            "tensor([[ 5.0000,  0.2000],\n",
            "        [-2.0000,  5.0000]])\n",
            "tensor([[ 0.8000, 20.0000],\n",
            "        [-2.0000,  0.8000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathbf{A} = \\begin{bmatrix}\n",
        "a & b \\\\\n",
        "c & d\n",
        "\\end{bmatrix}, \\quad\n",
        "\\mathbf{B} = \\begin{bmatrix}\n",
        "e & f \\\\\n",
        "g & h\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{A} \\odot \\mathbf{B} = \\begin{bmatrix}\n",
        "a \\cdot e & b \\cdot f \\\\\n",
        "c \\cdot g & d \\cdot h\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "IwNp-imdxGg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathbf{Y_1} = \\begin{bmatrix}\n",
        "2 & 2 \\\\\n",
        "2 & 2\n",
        "\\end{bmatrix}, \\quad\n",
        "\\mathbf{X_{10}} = \\begin{bmatrix}\n",
        "2.5 & 0.1 \\\\\n",
        "-1.0 & 2.5\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{Y_4} = \\mathbf{Y_1} \\odot \\mathbf{X_{10}} = \\begin{bmatrix}\n",
        "2 \\cdot 2.5 & 2 \\cdot 0.1 \\\\\n",
        "2 \\cdot (-1.0) & 2 \\cdot 2.5\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "5.0 & 0.2 \\\\\n",
        "-2.0 & 5.0\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "DVwhrQ4MxOEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x6)\n",
        "print(x6[:, 0])\n",
        "print(x6[:, 1])\n",
        "print(x6[0, :])\n",
        "print(x6[1, :])\n",
        "print(x6[0, 0])\n",
        "print(x6[1, 0])\n",
        "print(x6[0, 1])\n",
        "print(x6[1, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdf1zkwBxLFu",
        "outputId": "a0e73200-4ac4-4d04-8709-cd2bc25d5a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0508, 0.2936],\n",
            "        [0.6220, 0.3142]])\n",
            "tensor([0.0508, 0.6220])\n",
            "tensor([0.2936, 0.3142])\n",
            "tensor([0.0508, 0.2936])\n",
            "tensor([0.6220, 0.3142])\n",
            "tensor(0.0508)\n",
            "tensor(0.6220)\n",
            "tensor(0.2936)\n",
            "tensor(0.3142)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x11 = torch.rand(2,2,2)\n",
        "print(x11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-y6Zx56z8tU",
        "outputId": "3de14f31-a2cf-40dc-98cf-d65c0ee646d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0355, 0.1472],\n",
            "         [0.4605, 0.4960]],\n",
            "\n",
            "        [[0.7705, 0.6248],\n",
            "         [0.9110, 0.9582]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x11[0, 0, 0])\n",
        "print(x11[0, 0, 1])\n",
        "print(x11[0, 1, 0])\n",
        "print(x11[0, 1, 1])\n",
        "print(x11[1, 0, 0])\n",
        "print(x11[1, 0, 1])\n",
        "print(x11[1, 1, 0])\n",
        "print(x11[1, 1, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xfcUpTL2NgF",
        "outputId": "95d29d68-328f-49e5-bf0f-33b4edf50cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9774)\n",
            "tensor(0.1755)\n",
            "tensor(0.4850)\n",
            "tensor(0.6023)\n",
            "tensor(0.3781)\n",
            "tensor(0.9620)\n",
            "tensor(0.7324)\n",
            "tensor(0.3758)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x11[0, 0, :])\n",
        "print(x11[0, 1, :])\n",
        "print(x11[1, 0, :])\n",
        "print(x11[1, 1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFlW6Gi36wjF",
        "outputId": "a75a9478-f05d-4813-9c91-e9309b24b9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9774, 0.1755])\n",
            "tensor([0.4850, 0.6023])\n",
            "tensor([0.3781, 0.9620])\n",
            "tensor([0.7324, 0.3758])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x11[0,:,:])\n",
        "print(x11[1,:,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPIAOUDv7g8M",
        "outputId": "847c4b29-abe8-4cbc-c60b-462db3a4c96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0355, 0.1472],\n",
            "        [0.4605, 0.4960]])\n",
            "tensor([[0.7705, 0.6248],\n",
            "        [0.9110, 0.9582]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x12 = torch.rand(4,4)\n",
        "print(x12)\n",
        "y6 = x12.view(16)\n",
        "print(y6)\n",
        "y7 = x12.view(2,8)\n",
        "print(y7)\n",
        "y8 = x12.view(4,4)\n",
        "print(y8, y8.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOdsRRFp8DuG",
        "outputId": "43422b12-87c9-4608-e6f3-4d3723bc1f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6572, 0.8081, 0.6113, 0.2607],\n",
            "        [0.2656, 0.0288, 0.9015, 0.7872],\n",
            "        [0.4054, 0.6026, 0.4408, 0.7878],\n",
            "        [0.0196, 0.0515, 0.7702, 0.4218]])\n",
            "tensor([0.6572, 0.8081, 0.6113, 0.2607, 0.2656, 0.0288, 0.9015, 0.7872, 0.4054,\n",
            "        0.6026, 0.4408, 0.7878, 0.0196, 0.0515, 0.7702, 0.4218])\n",
            "tensor([[0.6572, 0.8081, 0.6113, 0.2607, 0.2656, 0.0288, 0.9015, 0.7872],\n",
            "        [0.4054, 0.6026, 0.4408, 0.7878, 0.0196, 0.0515, 0.7702, 0.4218]])\n",
            "tensor([[0.6572, 0.8081, 0.6113, 0.2607],\n",
            "        [0.2656, 0.0288, 0.9015, 0.7872],\n",
            "        [0.4054, 0.6026, 0.4408, 0.7878],\n",
            "        [0.0196, 0.0515, 0.7702, 0.4218]]) torch.Size([4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y9 = x12.view(-1, 8)\n",
        "print(y9, y9.size())\n",
        "y10 = x12.view(-1, 4)\n",
        "print(y10, y10.size())\n",
        "y11 = x12.view(-1, 2)\n",
        "print(y11, y11.size())\n",
        "y12 = x12.view(-1, 1)\n",
        "print(y12, y12.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii-KWMb39OlI",
        "outputId": "3b600fd5-d949-4939-8e51-70627602b517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6572, 0.8081, 0.6113, 0.2607, 0.2656, 0.0288, 0.9015, 0.7872],\n",
            "        [0.4054, 0.6026, 0.4408, 0.7878, 0.0196, 0.0515, 0.7702, 0.4218]]) torch.Size([2, 8])\n",
            "tensor([[0.6572, 0.8081, 0.6113, 0.2607],\n",
            "        [0.2656, 0.0288, 0.9015, 0.7872],\n",
            "        [0.4054, 0.6026, 0.4408, 0.7878],\n",
            "        [0.0196, 0.0515, 0.7702, 0.4218]]) torch.Size([4, 4])\n",
            "tensor([[0.6572, 0.8081],\n",
            "        [0.6113, 0.2607],\n",
            "        [0.2656, 0.0288],\n",
            "        [0.9015, 0.7872],\n",
            "        [0.4054, 0.6026],\n",
            "        [0.4408, 0.7878],\n",
            "        [0.0196, 0.0515],\n",
            "        [0.7702, 0.4218]]) torch.Size([8, 2])\n",
            "tensor([[0.6572],\n",
            "        [0.8081],\n",
            "        [0.6113],\n",
            "        [0.2607],\n",
            "        [0.2656],\n",
            "        [0.0288],\n",
            "        [0.9015],\n",
            "        [0.7872],\n",
            "        [0.4054],\n",
            "        [0.6026],\n",
            "        [0.4408],\n",
            "        [0.7878],\n",
            "        [0.0196],\n",
            "        [0.0515],\n",
            "        [0.7702],\n",
            "        [0.4218]]) torch.Size([16, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x13 = torch.ones(5)\n",
        "print(x13, type(x13))\n",
        "y13 = x13.numpy()\n",
        "print(y13, type(y13))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxq2trb69oRL",
        "outputId": "d42fa172-c68b-4184-8d00-8596aea1a8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.]) <class 'torch.Tensor'>\n",
            "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x13.add_(1)\n",
        "print(x13)\n",
        "print(y13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eun3LUE__C-y",
        "outputId": "050bac34-b936-4fe8-a557-30866ba75999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x14 = np.ones(5)\n",
        "print(x14, type(x14))\n",
        "y14 = torch.from_numpy(x14)\n",
        "print(y14, type(y14))\n",
        "\n",
        "x14 += 1\n",
        "print(x14)\n",
        "print(y14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjjMlYGUA26O",
        "outputId": "78178ee6-4eca-4895-b25b-54791f9b34bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64) <class 'torch.Tensor'>\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x15 = np.ones(5)\n",
        "print(x14, type(x14))\n",
        "y15 = np.array(x15)\n",
        "print(y15, type(y15))\n",
        "\n",
        "x15 += 1\n",
        "print(x15)\n",
        "print(y15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elROmbOEBPQP",
        "outputId": "ced042e5-0638-406a-b7e3-a9619857b49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.] <class 'numpy.ndarray'>\n",
            "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Calculation with Autograd"
      ],
      "metadata": {
        "id": "TPNjWXf3CXVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "Q2EkzjvZE_jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "zQmpcBH3F6FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3AUjunsFqgC",
        "outputId": "592044b4-ea9a-4116-c641-cf66cacda616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.2255, -0.6651,  0.8562], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x+2\n",
        "print(y)\n",
        "\n",
        "z = y*y*2\n",
        "print(z)\n",
        "\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbD5LZ0yFs1K",
        "outputId": "c0c88281-f1ce-4f57-e862-fd8d3d2c4f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7745, 1.3349, 2.8562], grad_fn=<AddBackward0>)\n",
            "tensor([ 1.1997,  3.5639, 16.3154], grad_fn=<MulBackward0>)\n",
            "tensor(7.0263, grad_fn=<MeanBackward0>)\n",
            "tensor([ 3.0979,  5.3396, 11.4247])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.randn(3, requires_grad=True)\n",
        "print(x1)"
      ],
      "metadata": {
        "id": "RGVsR-AvQkRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfed1ed-d7d8-4cd2-c70b-bd893479dd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3984,  2.6293, -0.1409], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = x1+2\n",
        "print(y1)\n",
        "\n",
        "z1 = y1*y1*2\n",
        "print(z1)\n",
        "\n",
        "v = torch. tensor ([0.1, 1.0, 0.0011], dtype=torch.float32)\n",
        "\n",
        "z1.backward(v) #\\sum_{i=1}^{j=3}{z1_{i}v_{i}}\n",
        "print(x1.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdyN2vFvA2g_",
        "outputId": "8c7ee7ec-72e7-4fff-e982-aaca5f8978a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.6016, 4.6293, 1.8591], grad_fn=<AddBackward0>)\n",
            "tensor([ 5.1302, 42.8616,  6.9122], grad_fn=<MulBackward0>)\n",
            "tensor([ 3.4167, 43.2072,  2.4951])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "print(weights)\n",
        "\n",
        "for epoch in range (3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  #weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCmitO3kA_bu",
        "outputId": "191878d3-7bce-48b5-f581-2b70d6cd61dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient of a Loss Function"
      ],
      "metadata": {
        "id": "DdE8DBuqNUaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "L5thrZfgV0Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ALV4VE6AV339"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "print(w)\n",
        "x = torch.tensor(1.0, dtype=torch.float32)\n",
        "print(x)\n",
        "y = torch.tensor(2.0, dtype=torch.float32)\n",
        "print(y)\n",
        "\n",
        "y_hat = w*x\n",
        "print(y_hat)\n",
        "\n",
        "s = y_hat - y\n",
        "print(s)\n",
        "\n",
        "loss = (s)**2\n",
        "print(loss)\n",
        "\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slNHuLS-T44_",
        "outputId": "19d0ae16-eb39-4a8d-87da-417923efab39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., requires_grad=True)\n",
            "tensor(1.)\n",
            "tensor(2.)\n",
            "tensor(1., grad_fn=<MulBackward0>)\n",
            "tensor(-1., grad_fn=<SubBackward0>)\n",
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Manually Impletment Gradient Decent"
      ],
      "metadata": {
        "id": "tZO2VtjdUh5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "1WJ1xJXznEa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "6PUYWy_UnJba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y = w*X\n",
        "#y = 2*X\n",
        "\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32) #Input values\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32) #Known values\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "#Model prediciton\n",
        "\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "#loss = MSE, MSE = 1/N * (w*x - y)**2\n",
        "\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "#Gradient = the differential of MSE w.r.t. w == 1/N *2x * (w*x - y)\n",
        "\n",
        "def gradient(x, y, y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "print(f'Prediction before training: y(5) = {forward(5):.10f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients\n",
        "  dw = gradient(X, Y, y_pred)\n",
        "\n",
        "  # update weights\n",
        "  w = w - learning_rate * dw #c -= a is equivalent to c = c - a\n",
        "\n",
        "  if epoch %2  == 0: # %1 would print every step, %2 would print every other step\n",
        "    print(f'epoch {epoch+1}: w = {w:.10f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: y(5) = {forward(5):.10f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og8lgsounLF2",
        "outputId": "d42fd1a8-128a-4a14-bc5a-d49cd1503248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: y(5) = 0.0000000000\n",
            "epoch 1: w = 1.2000000000, loss = 30.00000000\n",
            "epoch 3: w = 1.8719999886, loss = 0.76800019\n",
            "epoch 5: w = 1.9795200133, loss = 0.01966083\n",
            "epoch 7: w = 1.9967231870, loss = 0.00050331\n",
            "epoch 9: w = 1.9994756985, loss = 0.00001288\n",
            "epoch 11: w = 1.9999160600, loss = 0.00000033\n",
            "epoch 13: w = 1.9999865985, loss = 0.00000001\n",
            "epoch 15: w = 1.9999978352, loss = 0.00000000\n",
            "epoch 17: w = 1.9999996305, loss = 0.00000000\n",
            "epoch 19: w = 1.9999999166, loss = 0.00000000\n",
            "Prediction after training: y(5) = 9.9999999762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch backprop training pipeline"
      ],
      "metadata": {
        "id": "Vx67J17kMrqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "2-Kdv9OFEiF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "gKU4xsw2Bh7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) #Input values\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) #Known values\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "#Model prediciton\n",
        "\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "#loss = MSE, MSE = 1/N * (w*x - y)**2\n",
        "\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: y(5) = {forward(5):.10f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients\n",
        "  l.backward()\n",
        "  w_grad = w.grad\n",
        "\n",
        "  # update weights\n",
        "  with torch.no_grad(): # When we do l.backward(), it assigns a dl/dw = a,, where a is some constant, and a = w.grad. if we do w -= learning_rate * w.grad, we are interfering with the initial value of w used to calculate w.grad\n",
        "  # Assume that with torch.no_grad(): \"pauses\" the computational graph created from the l.backward()\n",
        "    w -= learning_rate * w_grad\n",
        "\n",
        "  # zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch %2  == 0: # %1 would print every step, %2 would print every other step\n",
        "    print(f'epoch {epoch+1}: w = {w:.10f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: y(5) = {forward(5):.10f}') #Backpropagation is not as exact as the numerical impletmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_IximptDl0U",
        "outputId": "0305b2e4-ebde-454a-ed52-3c07be6ad5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: y(5) = 0.0000000000\n",
            "epoch 1: w = 0.2999999821, loss = 30.00000000\n",
            "epoch 3: w = 0.7717499137, loss = 15.66018772\n",
            "epoch 5: w = 1.1125893593, loss = 8.17471695\n",
            "epoch 7: w = 1.3588458300, loss = 4.26725292\n",
            "epoch 9: w = 1.5367661715, loss = 2.22753215\n",
            "epoch 11: w = 1.6653136015, loss = 1.16278565\n",
            "epoch 13: w = 1.7581890821, loss = 0.60698116\n",
            "epoch 15: w = 1.8252916336, loss = 0.31684780\n",
            "epoch 17: w = 1.8737732172, loss = 0.16539653\n",
            "epoch 19: w = 1.9088011980, loss = 0.08633806\n",
            "Prediction after training: y(5) = 9.6124057770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch Loss, and Optimizer training pipeline"
      ],
      "metadata": {
        "id": "2G-rMyf5Mkrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "2lBAoUMNM9qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "ewPww3saM_C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32) #Input values\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32) #Known values\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "#Model prediciton\n",
        "\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "\n",
        "print(f'Prediction before training: y(5) = {forward(5):.10f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss() #nn.MSELoss is a class, and to use it, you should first create an instance of the class and then call the instance with the input and target tensors (https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L548, line 548)\n",
        "optimiser = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients\n",
        "  l.backward()\n",
        "  w_grad = w.grad\n",
        "\n",
        "  # update weights\n",
        "  optimiser.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimiser.zero_grad()\n",
        "\n",
        "  if epoch %2  == 0: # %1 would print every step, %2 would print every other step\n",
        "    print(f'epoch {epoch+1}: w = {w:.10f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: y(5) = {forward(5):.10f}') #Backpropagation is not as exact as the numerical impletmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBp6SAQ7M_q3",
        "outputId": "2ea39a47-8a90-4703-85c7-2e85747331a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: y(5) = 0.0000000000\n",
            "epoch 1: w = 0.2999999821, loss = 30.00000000\n",
            "epoch 3: w = 0.7717499137, loss = 15.66018772\n",
            "epoch 5: w = 1.1125893593, loss = 8.17471695\n",
            "epoch 7: w = 1.3588458300, loss = 4.26725292\n",
            "epoch 9: w = 1.5367661715, loss = 2.22753215\n",
            "epoch 11: w = 1.6653136015, loss = 1.16278565\n",
            "epoch 13: w = 1.7581890821, loss = 0.60698116\n",
            "epoch 15: w = 1.8252916336, loss = 0.31684780\n",
            "epoch 17: w = 1.8737732172, loss = 0.16539653\n",
            "epoch 19: w = 1.9088011980, loss = 0.08633806\n",
            "epoch 21: w = 1.9341088533, loss = 0.04506890\n",
            "epoch 23: w = 1.9523936510, loss = 0.02352631\n",
            "epoch 25: w = 1.9656044245, loss = 0.01228084\n",
            "epoch 27: w = 1.9751492739, loss = 0.00641066\n",
            "epoch 29: w = 1.9820452929, loss = 0.00334642\n",
            "epoch 31: w = 1.9870276451, loss = 0.00174685\n",
            "epoch 33: w = 1.9906275272, loss = 0.00091188\n",
            "epoch 35: w = 1.9932283163, loss = 0.00047601\n",
            "epoch 37: w = 1.9951075315, loss = 0.00024848\n",
            "epoch 39: w = 1.9964652061, loss = 0.00012971\n",
            "epoch 41: w = 1.9974461794, loss = 0.00006770\n",
            "epoch 43: w = 1.9981548786, loss = 0.00003534\n",
            "epoch 45: w = 1.9986668825, loss = 0.00001845\n",
            "epoch 47: w = 1.9990367889, loss = 0.00000963\n",
            "epoch 49: w = 1.9993040562, loss = 0.00000503\n",
            "epoch 51: w = 1.9994971752, loss = 0.00000262\n",
            "epoch 53: w = 1.9996367693, loss = 0.00000137\n",
            "epoch 55: w = 1.9997375011, loss = 0.00000071\n",
            "epoch 57: w = 1.9998103380, loss = 0.00000037\n",
            "epoch 59: w = 1.9998630285, loss = 0.00000019\n",
            "epoch 61: w = 1.9999010563, loss = 0.00000010\n",
            "epoch 63: w = 1.9999284744, loss = 0.00000005\n",
            "epoch 65: w = 1.9999482632, loss = 0.00000003\n",
            "epoch 67: w = 1.9999625683, loss = 0.00000001\n",
            "epoch 69: w = 1.9999729395, loss = 0.00000001\n",
            "epoch 71: w = 1.9999804497, loss = 0.00000000\n",
            "epoch 73: w = 1.9999859333, loss = 0.00000000\n",
            "epoch 75: w = 1.9999898672, loss = 0.00000000\n",
            "epoch 77: w = 1.9999927282, loss = 0.00000000\n",
            "epoch 79: w = 1.9999947548, loss = 0.00000000\n",
            "epoch 81: w = 1.9999963045, loss = 0.00000000\n",
            "epoch 83: w = 1.9999973774, loss = 0.00000000\n",
            "epoch 85: w = 1.9999980927, loss = 0.00000000\n",
            "epoch 87: w = 1.9999985695, loss = 0.00000000\n",
            "epoch 89: w = 1.9999990463, loss = 0.00000000\n",
            "epoch 91: w = 1.9999992847, loss = 0.00000000\n",
            "epoch 93: w = 1.9999995232, loss = 0.00000000\n",
            "epoch 95: w = 1.9999996424, loss = 0.00000000\n",
            "epoch 97: w = 1.9999996424, loss = 0.00000000\n",
            "epoch 99: w = 1.9999996424, loss = 0.00000000\n",
            "Prediction after training: y(5) = 9.9999980927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch Model training pipeline"
      ],
      "metadata": {
        "id": "tdRbCzaxP2cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "ajyyxU4LQvJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "CpQb3Sc3QxTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "X1 = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "print(X, X1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2UWeUDER19n",
        "outputId": "33a0d321-ee37-4b1b-c064-02aba4a24c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.]) tensor([[1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32) #Input values\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) #Known values\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples,n_features)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "print(f'Prediction before training: y(5) = {model(X_test).item():.10f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients\n",
        "  l.backward()\n",
        "\n",
        "  # update weights\n",
        "  optimiser.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimiser.zero_grad()\n",
        "\n",
        "  if epoch %10  == 0: # %1 would print every step, %2 would print every other step\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: y(5) = {model(X_test).item():.10f}') #Backpropagation is not as exact as the numerical impletmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-A6grmqQqHV",
        "outputId": "e0863bab-10db-46aa-bab6-fe3400e3b654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Prediction before training: y(5) = 3.2287712097\n",
            "epoch 1: w = Parameter containing:\n",
            "tensor([[0.8126]], requires_grad=True), loss = 13.31583691\n",
            "epoch 11: w = Parameter containing:\n",
            "tensor([[1.6523]], requires_grad=True), loss = 0.39437073\n",
            "epoch 21: w = Parameter containing:\n",
            "tensor([[1.7920]], requires_grad=True), loss = 0.05715982\n",
            "epoch 31: w = Parameter containing:\n",
            "tensor([[1.8189]], requires_grad=True), loss = 0.04570219\n",
            "epoch 41: w = Parameter containing:\n",
            "tensor([[1.8276]], requires_grad=True), loss = 0.04283170\n",
            "epoch 51: w = Parameter containing:\n",
            "tensor([[1.8332]], requires_grad=True), loss = 0.04033324\n",
            "epoch 61: w = Parameter containing:\n",
            "tensor([[1.8383]], requires_grad=True), loss = 0.03798554\n",
            "epoch 71: w = Parameter containing:\n",
            "tensor([[1.8431]], requires_grad=True), loss = 0.03577454\n",
            "epoch 81: w = Parameter containing:\n",
            "tensor([[1.8477]], requires_grad=True), loss = 0.03369228\n",
            "epoch 91: w = Parameter containing:\n",
            "tensor([[1.8522]], requires_grad=True), loss = 0.03173124\n",
            "Prediction after training: y(5) = 9.7036371231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "nMMHomM9RkwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "aWSB_CFQdJ1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JEIiOgEFdKeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Prepare data\n",
        "#create a synthetic dataset, with gaussian distribution for a regression problem, 100 data points for X and Y\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "print(X_numpy[:5], y_numpy[:5])\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32)) #torch.from_numpy: used to create a PyTorch tensor from a NumPy array\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "\n",
        "print(X[:5], y[:5])\n",
        "\n",
        "y = y.view(y.shape[0], 1) #view is a built in PyTorch to reshape the tensor\n",
        "\n",
        "n_samples, n_features = X.shape # X.shape = [100,1], therefore, n_samples = 100, n_features = 1\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "#By providing input_size and output_size, you are specifying the dimensions of this linear transformation.\n",
        "#It will create a layer with input_size input neurons and output_size output neurons.\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy() #model(X).detach() generate a neew tensor such that it won't affect the computational graph\n",
        "print(predicted[:5]) #The predicted is the y values from the optimised w\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "oCmc0BVvJXE9",
        "outputId": "1bbb3c34-1ebe-43d8-b30a-d35aa70602ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.3474603 ]\n",
            " [ 0.3523434 ]\n",
            " [ 0.9546986 ]\n",
            " [ 0.03592805]\n",
            " [ 0.04800625]] [-126.24922409   50.92876904   63.15463302    6.05472009   -5.72954025]\n",
            "tensor([[-1.3475],\n",
            "        [ 0.3523],\n",
            "        [ 0.9547],\n",
            "        [ 0.0359],\n",
            "        [ 0.0480]]) tensor([-126.2492,   50.9288,   63.1546,    6.0547,   -5.7295])\n",
            "epoch: 10, loss = 3962.5957\n",
            "epoch: 20, loss = 2794.5884\n",
            "epoch: 30, loss = 1998.4133\n",
            "epoch: 40, loss = 1455.5820\n",
            "epoch: 50, loss = 1085.4025\n",
            "epoch: 60, loss = 832.9096\n",
            "epoch: 70, loss = 660.6537\n",
            "epoch: 80, loss = 543.1144\n",
            "epoch: 90, loss = 462.8955\n",
            "epoch: 100, loss = 408.1369\n",
            "[[-85.84004  ]\n",
            " [ 22.928724 ]\n",
            " [ 61.47284  ]\n",
            " [  2.6816165]\n",
            " [  3.4544885]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQdRJREFUeJzt3Xt8VPW19/HvTpCAhQSBQIBEAVGr1ku9paHiSWwOYD0WT4AqagvWYlVAEdRCb2gr0latoYr18lRo+whqMepj69HSmCitQXuwqa2KlRYKhCQqKQmgJjLZzx+bGWYye2b2XPdcPu/XK6+YPXtmfqSWWa7f+q1lmKZpCgAAIEPlub0AAACAeBDMAACAjEYwAwAAMhrBDAAAyGgEMwAAIKMRzAAAgIxGMAMAADIawQwAAMho/dxeQCr09vZq9+7dGjx4sAzDcHs5AADAAdM0tW/fPo0ePVp5eaHzLzkRzOzevVtlZWVuLwMAAMRg586dKi0tDfl4TgQzgwcPlmT9MgoLC11eDQAAcKKrq0tlZWW+z/FQciKY8W4tFRYWEswAAJBhIpWIUAAMAAAyGsEMAADIaAQzAAAgoxHMAACAjEYwAwAAMhrBDAAAyGgEMwAAIKMRzAAAgIyWE03zAADIWR6PtHGj1NoqjRolTZok5ee7vaqEIpgBACBb1dVJN9wg7dp1+FppqbRypVRT4966EoxtJgAAslFdnTRjRmAgI0ktLdb1ujp31pUEBDMAAGQbj8fKyJhm8GPeawsXWvdlAYIZAACyzcaNwRkZf6Yp7dxp3ZcFCGYAAMg2ra2JvS/NUQAMAEC2GTUqsfeFkiYnpcjMAACQbSZNsk4tGYb944YhlZVZ98Wqrk4aO1aqqpIuu8z6PnasK4XFBDMAAGSb/Hzr+LUUHNB4f66tjT2LkmYnpQhmAADIRjU10vr10pgxgddLS63rsfaZScOTUtTMAACQrWpqpGnTElvXEs1JqcrK2N8nCgQzAABks/z8xAYVaXhSim0mAADgXKpOSkWBzAwAAOkmTY482/KelGppsa+bMQzr8XhOSkWJzAwAAOkkjY4820r2SakYEMwAAJAuIh15/vWvpcZGad0667tbs5WSdVIqRoZp2uWIsktXV5eKiorU2dmpwsJCt5cDAEAwj8fKwIQ7KZSfHxjAlJZaWZIUBw8+Sd4Oc/r5Tc0MAADpINKRZyk4E+PN2LiQDZGU+JNSMWKbCQCAdBDLUWaXmtSlG4IZAADSQaxHmf2b1OUoghkAANJBpOGQkaSwSV26IZgBACAdhDvy7EQKm9R59fZaO1x33unuLhfBDAAA6SLUkedwJ4QMQyorS2mTOkmqrz8cf91yi1WL7BZOMwEAkE7shkN+8IH05S9bj/t3VHGhSV1PjzRhglWm4/XZz0pHH52St7dFMAMAQLqxO/K8fr10ww2Bx7dLS61AJkXHsh97TJo1K/Da//yPNHVqSt4+JIIZAAAygV3GJkUzm/btk/r2rDvnHKmpScpLg4IVghkAADKFC03qamulG28MvPbaa9LZZ6d0GWElNZ56+eWXddFFF2n06NEyDENPP/10wONz5syRYRgBX1P75Ko6Ojp0+eWXq7CwUEOGDNFVV12l/fv3J3PZAADkvPZ2qyTHP5CZOdM6wZROgYyU5GDmwIEDOu2007Rq1aqQ90ydOlWtra2+r3Xr1gU8fvnll+vNN9/Uhg0b9Jvf/EYvv/yyrr766mQuGwCAnHbzzVJJSeC1v/9deuKJ2NvgJFNSt5kuuOACXXDBBWHvKSgoUEnf39ghb7/9tp5//nn96U9/0llnnSVJuvfee/XFL35Rd911l0aPHp3wNQMA4IokD210YutW6bjjAq8tWiTdfXdKlxE118t2GhsbNWLECJ1wwgm69tprtWfPHt9jTU1NGjJkiC+QkaTq6mrl5eXp1VdfDfma3d3d6urqCvgCACBt1dVZE7OrqqTLLrO+jx1rXU8B05QuuSQ4kGltTf9ARnI5mJk6dap++ctfqr6+Xj/60Y/00ksv6YILLpDnUBvBtrY2jRgxIuA5/fr109ChQ9XW1hbydVesWKGioiLfV1lZWVL/HAAAxKyuzpp83XditncidpIDmv/9X+tE0hNPHL52991WgBNi4yTtuHqa6dJLL/X98ymnnKJTTz1Vxx57rBobG/WFL3wh5tddunSpFi1a5Pu5q6uLgAYAkH48Hqt3jH8jPC/TtApUFi60jmQneMupt1eaOFHqu9HR1SUNHpzQt0o617eZ/I0fP17Dhw/X1q1bJUklJSV67733Au45ePCgOjo6QtbZSFYdTmFhYcAXAABpZ+PG4IyMvyRNxH7hBSs28g9k1q613i7TAhkpzfrM7Nq1S3v27NGoQ8OyKioqtHfvXm3evFlnnnmmJOnFF19Ub2+vysvL3VwqACCTpEFxrS2nk64TNBG7u1s65hjr2LVXaan0j39I/fsn5C1ckdTMzP79+9Xc3Kzm5mZJ0rZt29Tc3KwdO3Zo//79uvnmm7Vp0yZt375d9fX1mjZtmiZMmKApU6ZIkk488URNnTpVc+fO1WuvvaY//vGPmj9/vi699FJOMgEAnHG5uDYsp5OuEzAR+1e/kgYMCAxkNmywEj+ZHMhIkswkamhoMCUFfc2ePdv88MMPzcmTJ5vFxcXmEUccYR5zzDHm3Llzzba2toDX2LNnjzlr1ixz0KBBZmFhoXnllVea+/bti2odnZ2dpiSzs7MzkX88AEC6e/JJ0zQM07R2UA5/GYb19eST7q7v4EHTLC21X6N3nWVl1n0x2rEj+GXPPdc0PZ4E/jmSxOnnt2GadlVH2aWrq0tFRUXq7OykfgYAcoXHY2VgQtWkGIa1x7Jtm/2WU6q2prynmST7idjr18c8SHLECOn99wOvvf66NeU6Ezj9/E6rAmAAABImnuLaVG5N1dRYAcuYMYHXS0tjDmRef92KhfwDmeJi64+cKYFMNNKqABgAgISJtbjWmynpu3Hh7fsSR6YkpAROxLYbN/D730txdDxJewQzAIDsFEtxrYt9X+KdiP3ss9KXvhR8PfuLSdhmAgBkq0mTrK2aUJMRDUMqK7Pu83Kp70s8vDFW30DmzTdzI5CRCGYAANkqP19audL6574Bjffn2trADEuK+77Ea+VKaxSBvxNOsIKYk05yZ01uIJgBAGSvaItrU9j3JR49PYd3vPy1tUlbtriyJFdxNBsAkP2cHrP2HuduabHfo4l0nDsFvvQlqz7G35e/LD3+uCvLSSqnn98UAAMAsp/T4lrv1tSMGVbgYtf3pe/WVIq0tkp2ze8//FAaODDly0krbDMBAOAvCX1f4mUYwYHMsmVWrJXrgYxEZgYAgGAJ7PsSjz//WTrjjODrBw+mx5zMdEEwAwCAnTj7vsTL7kT5LbdIP/pR6teS7ghmAABIIytXBp9SknKnZ0wsCGYAAEgTdtmYX/1KuuKK1K8lkxDMAADgstNOk954I/g62RhnOM0EAIBLenutbEzfQOa3vyWQiQaZGQAAXBBqZBRBTPTIzAAAkEIdHfaBzOuvE8jEiswMAAApQjYmOcjMAADSn8cjNTZK69ZZ3z0et1cUleZm+0Bmzx4CmUQgMwMASG91ddINN0i7dh2+VlpqNWRxYbRAtMjGJB+ZGQBA+qqrs4Y++gcykjXVesYM6/E09X//r30gc/AggUyiEcwAANKTx2NlZOw++b3XFi5Myy0nw5C+8pXAa6ecYi2bmUqJRzADAEhPGzcGZ2T8maa0c6d1X5q45hr7bIxp2jfFQ2IQzAAA0lNra2LvSzLDkB58MPDaTTexpZQKFAADANLTqFGJvS9JjjlG2rEj+DpBTOqQmQEApKdJk6xTS6GOAxmGVFZm3eeCgwetJfQNZNavJ5BJNTIzAID0lJ9vHb+eMcOKGvwjBG+AU1vrSkUtx63TC5kZAED6qqmxUh1jxgReLy21rqe4z0x7u30g89ZbBDJuIjMDAEhvNTXStGnWqaXWVqtGZtKklGdkyMakL4IZAED6y8+XKitdeetNm6SKiuDrnZ1SYWHq14NgBDMAAIRANiYzUDMDAEAfP/iBfSDT20sgk47IzAAA4PH4anKMy2YFPVxebm03IT0RzABAtvD7QHarSDYjHZrKffauOv2vggMZMjHpj2AGALLBoQ/kgFlGpaVWn5YUH1/OKIemchtmb9BD1+gB/ezJEZL4/aW7pNbMvPzyy7rooos0evRoGYahp59+OuBx0zT1ve99T6NGjdLAgQNVXV2td999N+Cejo4OXX755SosLNSQIUN01VVXaf/+/clcNgBklkMfyEFDGVtarOt1de6sK915PDKm19gGMqYM/cy4Lm2nciNQUoOZAwcO6LTTTtOqVatsH//xj3+sn/70p3rggQf06quv6lOf+pSmTJmijz/+2HfP5ZdfrjfffFMbNmzQb37zG7388su6+uqrk7lsAMgcHo+VkbHbC/Fe4wM5yIcfSka/4C24B3W1TB2q/E3DqdywZ5hmanYDDcPQU089pYsvvliSlZUZPXq0Fi9erJtuukmS1NnZqZEjR2rNmjW69NJL9fbbb+ukk07Sn/70J5111lmSpOeff15f/OIXtWvXLo0ePdrRe3d1damoqEidnZ0qpCkAgGzS2ChVVUW+r6HBtT4t6SbkcWuFeGDtWmlWcC0Nks/p57drR7O3bdumtrY2VVdX+64VFRWpvLxcTU1NkqSmpiYNGTLEF8hIUnV1tfLy8vTqq6+mfM0AkHZaWxN7XxZ75x37QKZZp4UOZCTXp3IjMtcKgNva2iRJI0eODLg+cuRI32NtbW0aMWJEwOP9+vXT0KFDfffY6e7uVnd3t+/nrq6uRC0bANKL0w/aHP9ADpmNKS2zaovs9igMwyqidmkqN5zLyqZ5K1asUFFRke+rrKzM7SUBQHJMmmR94Ib6tDYMqawsZz+QH3jA/lfT2XmopGjlSutC35tcnsqN6LgWzJSUlEiS2tvbA663t7f7HispKdF7770X8PjBgwfV0dHhu8fO0qVL1dnZ6fvauXNnglcPAGkiP58P5BAMQ7r22uDrpuk3UynNpnIjNq4FM+PGjVNJSYnq6+t917q6uvTqq6+q4tBEr4qKCu3du1ebN2/23fPiiy+qt7dX5eXlIV+7oKBAhYWFAV8AkLX4QA4weXKUowhqaqTt260i6bVrre/btuXc7y2TJbVmZv/+/dq6davv523btqm5uVlDhw7V0UcfrYULF+r222/Xcccdp3Hjxum73/2uRo8e7TvxdOKJJ2rq1KmaO3euHnjgAX3yySeaP3++Lr30UscnmQAgJ9TUSNOm5XwH4JgHQ7o4lRvxS+rR7MbGRlXZHBmcPXu21qxZI9M0tWzZMj300EPau3evzj33XN1///06/vjjffd2dHRo/vz5evbZZ5WXl6fp06frpz/9qQYNGuR4HRzNBgCXJXnUAtOts5PTz++U9ZlxE8EMALgoiaMWTFPKsymYmDpV+p//ieulkQacfn4zmwkAkDzeUQt9/7vZO2ohjpoesjHwysqj2QCANJCkUQt799oHMg89RCCTq8jMAACSY+PG4OGX/vxnHzksviUbAztkZgAAyeF0hEJ9vbRunTVnKkSWZuNG+0Dmr38lkAGZGQBAsjgdoXD77Yf/2aYwmGwMIiEzAwBIjkijFux4C4Pr6vStb9k/df9+AhkEIjMDAEgO76iFGTOsqMRJBGKakmHImG5/wokgBnbIzABArvN4rHqVCHUrMQk1aiGE0WqRYfYGXTdNAhmERmYGAHJZEhva+fQdtfDWW4F1MocYso9WCGIQCZkZAMhV3oZ2fY9P+9WtJIx39tGsWdIXvhDwkCHTNpAxGxoJZOAIwQwA5KIkNbRz5FBhcK/ybIOYyXpBZtnR1n2AA2wzAUAuSkJDO8fy82Xs2mn/tsah/8auXZ9zE78ROzIzAJCLnDa0c3qfQ7t22R+3XqnrZcqw6nXimNeE3ERmBgBykdOGdk7vcyBk87uGRqm1QhpVY20tkZFBlAhmACAXeRvatbTY180Yh7IkCahbefJJq564r7/+VfrMZySpMu73QG4jmAGAXBSuoZ03hVJbG3eWhFEESAVqZgAgV4VqaJeAupWpU+0DmY8+IpBB4pGZAYBs4vEcbk43alTkGpS+De2cPCcCsjFINYIZAMgWsXbz9Ta0ixNBDNzCNhMAZINUdvO1QSADNxHMAECmCDUQ0sVuvoZhH8gwGBKpxDYTAGSCcFtIQ4emvJtvT49UUBB8vbxc2rQpIW8BOEYwAwDJFm1Rbl/eLaS+qQ7vFtINNzh7nfr6hDSlY0sJ6YZtJgBIpro6aexYqapKuuwy6/vYsc5rWJxsIT36qLPXuv328O8dahvrkC1b7AOZBx4gkIG7DNPM/n8Fu7q6VFRUpM7OThUWFrq9HAC5IlRGxRsROOnl0thoBUCRFBdL778f+b5Q7x3hJBTZGLjB6ec3mRkASIZEFeU6HfRYXu7sPrv3DnMS6r7pDbaBzN//HiGQiZDlARKJmhkASIaNGxNTlOt00OOrrzpfm/97T5oUMugyzN6QTw8r1n43QIzIzABAMjjNqES6zzsQMtQ+jyQNH+5si8nuvW2CrjO0WYaCI5aeHoeBjIv9bpCbCGYAIBmcZlQi3ecdCCmFDmg+/tj5uvq+d59gypCpP+uMoFvNtet0xBERXs/FfjfIbQQzAJAMkTIqhiGVlVn3ReIdCDl0qP3j+/dHv778fGniRF8wZci0zcaYhx5xFJxFs7UGJBDBDAAkQ7iMivfn2lrnPV+mTZMGDEjY8uTxSK+8Ik2aZBvESFYgE1XQlaitNSBKBDMAkCzejMqYMYHXS0udHcv2t3GjVXeSQEZVpYx+wcGULxsTbdCVqK01IEoEMwCQTDU10vbtUkODtHat9X3btuhP9TjNZoTaivKzT4NsszGnHPG2FcR4RRt0JXJrDYgCR7MBINny8+OfieQ0m7FggbRqlfTBB7YPh9xSami0amheaYh97IJ3a23GDCtw8S8EjmVrDXCIzAwAZAInWY9hw6Tvf982kPmd/tM2kKnVDVY2pqpKOvZYqaNDmjXLCr5iCToSubUGOMQ4AwBwKt6BkfHy9nCRgrMepmkFM3v2BD0tbIFvwI1RjFmIxO3fFbJCxowzuPXWW2UYRsDXpz/9ad/jH3/8sebNm6dhw4Zp0KBBmj59utrb211cMYCcFO/AyEQIl/W47bagQOY/1GgbyLwz8rzgQEZKbC8Y79ZaPFkewCHXgxlJOvnkk9Xa2ur7+sMf/uB77MYbb9Szzz6rX//613rppZe0e/du1ZCmBJBK6dTVNlRB8XHHBdxmyNTL+o+gp5vf+a6Obw/T54VeMMhAaVEA3K9fP5WUlARd7+zs1M9//nOtXbtW559/viRp9erVOvHEE7Vp0yZ97nOfS/VSAeSaSF1tDcPKZEyblrrsg11BsV/zOzsHla989Ur6jrP3oBcMMkhaZGbeffddjR49WuPHj9fll1+uHTt2SJI2b96sTz75RNXV1b57P/3pT+voo49WU1OTW8sFkEtS1dU23inTEZrf5RumdSza6akqesEgg7iemSkvL9eaNWt0wgknqLW1VbfddpsmTZqkv/3tb2pra1P//v01ZMiQgOeMHDlSbW1tIV+zu7tb3d3dvp+7urqStXwA2S4VXW3jnDJt1e3aN7/zu8E6Fl1Zab12S4t9tskwrMfpBYMM4npm5oILLtDMmTN16qmnasqUKXruuee0d+9ePfHEEzG/5ooVK1RUVOT7KisrS+CKAeSUZHe1jbMeJ9RJ7ZDN7xI9ZgFIA64HM30NGTJExx9/vLZu3aqSkhL19PRo7969Afe0t7fb1th4LV26VJ2dnb6vnTt3JnnVALJWMrvaxjFl2jDsl2SaknnQE77jML1gkGXSLpjZv3+//vGPf2jUqFE688wzdcQRR6i+vt73+DvvvKMdO3aooqIi5GsUFBSosLAw4AsAYpLMTEYM9TgtLWGyMd6YyMmx6ESNWQDSgOs1MzfddJMuuugiHXPMMdq9e7eWLVum/Px8zZo1S0VFRbrqqqu0aNEiDR06VIWFhVqwYIEqKio4yQTAuWgauNnd681k2NW11NbGHgBEWY8TMYiJViLGLABpwPVgZteuXZo1a5b27Nmj4uJinXvuudq0aZOKi4slSffcc4/y8vI0ffp0dXd3a8qUKbr//vtdXjWAjBFNcW2ke6dNS2xXW4d1Niv/eJYWXhZ8/fbbpW9/O/a3B7IF4wwAZC9vcW3fv+bs2vZHc2+ieDxWF+EwJ4sMs9f2qdn/Nzfg/PObYAZAdvIGCqFqUrxHkLdts352em8021N977W755lnbOctDdBH6taAoLfZutWaBwnkAqef365vMwFAUkRbXOv0XrsaEydbWXb3DB8uXXGFdOut0kMPWRkahRkMmfX/6QnEhmAGQHZKRrM7u3tDbU95+8SsX2/9bHfPBx9YBcSSVFoaMojp7Q1d/AuAYAZAtkpGs7u33rJGDXi3kJzMbfI+HiGtYuyy74dFNgaIjJoZANnJQXFtUM1MqHv78m4hDR0qVVXFtcyQW0pr1yXmxJS/aI6oA2nA6ed32jXNA4CEiKbZXbh77Xi3kJ55Jubl9coIOxhSl11mBUpjx0YcaeBIXZ31WlVViX9twGUEMwDSQ7xTo+1E07Y/1L12vNmbRx+NaVmGTOUr+Mi1KSNwppLkeEZTWHHOfwLSHdtMANwX59ToiGLpAFxfb3Wli2T4cGnPntBbWWPGSB9+KHV06A2dotP0RtBtefLIE66E0cnR8FCiOaLOlhPSDNtMADJDKrIGTmYV9b33pJOcvfYVV1jfQ21lzZoldXTIkGkbyJgywgcyku2MJsdimP8EZBqCGQDuiWNqdNI5PeU0bVrorazHH9ecVWfb1sbcq/nBW0qRRHOMPNrnxPLaQJrgaDYA90STNUj1QMRJk6yAJNJpKO+Wlc3cJqOffQYo6iDGK5pj5NE+J5bXBtIEmRkA7knnrEE0p6G89x/ayjKqKm0DmV0aYx/IfOtbVmAU6iSVYUhlZVbgFC1vUJaM1wbSBMEMAPekOmsQ7YmpaE5DHRIqZjBlaIx22z94/vnRBU7RiDYoAzIQwQwA96QyaxCuz0q4IKemRtq+XWpokNautb5v2xYUyBiG/R/D9rh1Xx5PTIGTY8l8bSANcDQbgLu8p5mkwNoUb2SQiA/bUPOTDMO6NmyYdbzaK8pj4SGzMWvXWYFTJEOHSg8/bL1fMrv00gEYGcbp5zfBDAD32fWZKSuztj/iDWQi9Vmx4zCQChnEeP9WbWx0Pu7AMMiSAH0QzPghmAEyQLKyBtEEFP7CNJPr6ZEKCuyfFvA3aqT5UA7fD8hVNM0DkFmiaWwXjVhPQoVoJmcY9oGMedAjs6ExsO7Gv/g2xvcDEBnBDIDsFu9JqEPBUEOD/bZSYaFkPhmmuNhbfDt0aFTvB8A5muYByG6Rmt9FMmpU6NqYgx5p+XJp+rLgB73jGLx1MEVFUnW1o/cDEB0yMwCyW7g+K+EYhs4v+IOMqsqgh9as8cvGLLMJZKTgcQyVlTSvA5KEYAZAZoqmAV6oPivDhlnfbZrJGWavGro/H/RSpinNHhxiOKbdzd46GJrXAUlDMAMg84RrgBeKXfO79nbpyScDghxDpgyzN+jp//73oWRLuOGYoXjrYGheByQFR7MBZJZwDfCk2IKCQ8fCjapK24cD3iqWo94NDYGDMmleBzji9PObAmAAmSNcVsQ0rYBm4UJrgnUUwYE1FLLS9iWDRHPayH+ytj/vMXQACcE2E4DMsXFj+DqVGHq1ROzi21e0p42ogwGSjswMgNRIxNaK06yIg/uiCmL81z5ihLOj3lHOdwIQO4IZAMlnN3splg97p1mRd98N+dC+fVajOzu2sYnd2ocNO7ytZfek226Tvv1tMjJAirDNBCC56kIcY/Y2lQt3AqkvbwO8SB5+2PaotmHYBzKmDJmlZcFrCbX2jg7re9+uvmVl1umo732PQAZIIYIZAMkTqWBXOtxUzon8fGnu3Mj37doVUDfzq1/Zbyudoc0ydeiBvsGVk2LjgQOl3//+8FHvbdvYVgJcwDYTgOSJpmDX6eme445zdt+hupmQtTHq80Df01BO1r5rlxVgzZrlbE0AkoLMDIDkSWDBrs+IEY5u+9TXvmwbyPw/XRQcyHj5B1fJWDuApCAzAyB5nBbsRnPc2cGxa0Om9HHw9ZBBTF/eE1dOMBgScB2ZGQDJ4y3YTdRwRY9HuvfekA8bVilv0PUP93msAl+nvEfHGQwJZASCGQDJk+jhihs3Hj5J1IddECNZO0cD/zdC/Ys//wBl7lz7AmAGQwJphWAGQHIlcriiTX1KqGyMedBzOA6Jpq6ltlZ65hlrcOWyZfb3MBgSSCsZE8ysWrVKY8eO1YABA1ReXq7XXnvN7SUBcMpuYnUsx5j71KeEzMbc9v3AjInTupbbbrO+2/WW8b+HI9hAWsmIYObxxx/XokWLtGzZMr3++us67bTTNGXKFL333ntuLw1AJB6PNWn6scek5maptzf21/rgAyk/P3Q2RobMYcOt7rv+ItW/SNbjS5aE7i0jWc//P/8n9vUDSArDNMMNF0kP5eXlOvvss3XfffdJknp7e1VWVqYFCxZoyZIlEZ/vdIQ4gASzGwXgFe04g7o6tU2fp1Gy3zLynVR68kn71/R285UCgxVvgLN+vdXRt6oq8loaGph6DaSA08/vtM/M9PT0aPPmzaqurvZdy8vLU3V1tZqammyf093dra6uroAvACkWahSA165doccZeLM569ZZ33t6ZEyvsQ1kzEN5GknB4wX8OandobcMkJHSPpj54IMP5PF4NHLkyIDrI0eOVFtbm+1zVqxYoaKiIt9XWVkURzIBxC/cKAB/phk8zqCuziq+raqSLrtMd1b9VkZB/6CnVunF4L4xHR3S9Omh5z1Fqt1x2JDP8X0AUiIrm+YtXbpUixYt8v3c1dVFQAOkUqRRAP78xxl4szmHgqCQBb6Rmt9dfbU1ksDu2HR+fvxbRC++aL3OpEkczQbSQNpnZoYPH678/Hy1t7cHXG9vb1dJSYntcwoKClRYWBjwBSCFot2GaW0NyOaEKvDdqHOddfHds0davjy6NUiS00MFd9xhZY7Gjo1u6jeApEj7YKZ///4688wzVV9f77vW29ur+vp6VVRUuLgyACFF2+J/1ChfNidcNuZc/dH5a65c6Xwat/86otF30jYAV6R9MCNJixYt0sMPP6xf/OIXevvtt3XttdfqwIEDuvLKK91eGgA7To5Cex3quGtUVdoGMgeV73ymkr+ODkdznAJEs27pcE1Q37ofACmVEcHMJZdcorvuukvf+973dPrpp6u5uVnPP/98UFEwgDThP8YgHMOQamtl9LOvOzFlKF99+tIMHOh8HdFud4UbvxCK/6RtAK7IiGBGkubPn69//etf6u7u1quvvqry8nK3lwQgHO9R6NJS+8fLymSYvTKmB/eECThu7eUd7LhwofM1xDLROtQR7kg4rg24JiOa5sWLpnlAknk8VmaitfXwxGnvKR/vYy0t0vvvS8XFMkePUd75lbYvZRqH/hsrVGO7oiLJr+9USMXF1npiPW3kXXd9vXT77ZHvp5EekHBOP78JZgDEx67Lb5juvqF2b3x/E9m9XlmZNQCypsYKMkaOtE4shfPrXx/u+BsPj8c6tdTSEnqCdmmp1a+GY9pAQmVNB2AAaSxUl1+bUz5btzoIZKTIje3y86WHHgq/rptvTkwg432/UHU03p9rawlkABeRmQEQG2/GIlRzPL+MRcgC33j+9qmrk66/3gqcvIYPl+6/X5o5M44XDvN+4TJGABKObSY/BDOAQ+FqX/pqbIw4lHGR7tY9WhR0/brrpFWrUrzeREj1+wE5zunnd1aOMwAQgyhrXyKd3gnZ/C6W/3wKFUQkYjRBNFL9fgAcoWYGQFS1Lz4hjj2HGkXw9tsxBjJ9Bk/GNEag7xRuGtwBWYVtJiDXRVH7ErClYnPKJ6HZGClo8GTAmiTrqHakepVoM04A0ganmYBc5zQbEWnCdagOt36nfEJlY3rX18UeyPgNnrRdkxR5jEAsGScAGYdgBshG0WzNOO1ca3dfTY0Mszf4uiTzyTrb7r6OxRpkeSUiGAKQEQhmgGwTbTbCacv/PvcZhn3fGLOhUeZBT/xbOPEEWVL8wRCAjEEwA2STSNkI05SuuUbq6Tl8PdKkaO9MpIkTpcZG9T66Lnzzu8pKZ8eVI22DxRhk+cQbDAHIGAQzQDaJlI2QrPlIpaWHMzROOtxeeql07LEyqiqVf8WsoJf0xkmOOdkGcxpkTZpk/3i8wRCAjEEwA2QTp1mG998P3HIKNSm6tFS66Sa9dudLMnbttH0p88koi2idboPFO0Yg3mAIQMbgaDaQTRx05fWxO3LdtzndxIkyCvrbPt2UEf2QxViOgcczRsAbOEmhp3BzPBtIWxzNBnJRpGyEP7sCWG+H21mz9KWfVNoGMrdqmRXIhHqNcGIpyo00eDKccBknAhkgazDOAMgm3q2ZaCZG22xNhSzwVYgH6uudzSmKtSg3njECNTXStGnMVAKyGJkZINt4sxHDhzu7368ANtRx650qDR3ISNLttzsbMeBWUa5fxsnxaSsAGYNgBsgW/kedhw6VduyQiotD39+nADZkNqa0TKXG7sjv76SrLkW5AJKAYAZIJLcGGtoddT7+eGnOHPt0i99pIKNfvn3zO+9x61AniuyeIIXvqhvvCSUAsEEwAyRKIqY7x/q+oY4633WXdNNNIQtgQ40bCDjjGKqINtQTIxUEU5QLIME4mg0kQiKmO8fC6VHnrVulV17xFcAaVZW2t4f928DjkW691aqPiWTtWqs+JZy+x8ApygXQh9PPb4IZIF6x9E5JFKd9ZRoapMpK9fRIBQX2tzj6myDK9wOAeNBnBkgVNwcaRnHU2TDsA5moRhFQwAsgDRHMAPFyc6ChgyPMjfoPGZcFb/kcdZSDIKZvQbNEAS+AtEMwA8TLzYGGETIlhkxVqTHoumlKHR0RXjtUQbNEAS+AtEIwA8TLza2XEEed/1O/k6HgtMu6dQ63lCINg5RiHzEAAAlGATCQCG4PNPQbxmgXxPRdVlhuFjQDgB8KgIFUcrt3Sk2NjF07bQOZzs4oAhnJ3YJmAIgBgyaBRHFxoGHIUQSx5F3dLGgGgBgQzACJFM905xiayMUUxER6HzcLmgEgBgQzQDp0ovWrefEpLbWKe0NsUcUUyDh5H29Bc0uL/Yt5a2boJQMgTVAzg9zm1jylvmsId3Koz1rs5kZKDprfOX0fhkECyDCcZkLucmuekr8oTg7t/yhfgwfb3+ao+V20J5TssjhlZVYgwxFsACnAbCY/BDMIki7Hjx3OOor7uHWsM5XSYQsOQM7iaDYQTrocP45wIuhZ/ZdtIPPf/x3lSaVYTyh5C5pnzbK+E8gASEOuBjNjx46VYRgBXz/84Q8D7nnjjTc0adIkDRgwQGVlZfrxj3/s0mqRVdLl+HGYE0GGTH1JzwZdN80YSno4oQQgi7memfn+97+v1tZW39eCBQt8j3V1dWny5Mk65phjtHnzZt1555269dZb9dBDD7m4YmSFdPlwtxmFUK0NttmYl16KsW9MiPcJwLRrABnM9aPZgwcPVklJie1jjz76qHp6evTII4+of//+Ovnkk9Xc3Kyf/OQnuvrqq1O8UmSVdDl+7D05NGOGZBgyzF7b2+KubOvzPrYjFzihBCBDuZ6Z+eEPf6hhw4bps5/9rO68804dPHjQ91hTU5POO+889e/f33dtypQpeuedd/Tvf/875Gt2d3erq6sr4AsIkE7Hj2tqZJi9toFM92NPxR/I+L0P064BZCNXMzPXX3+9zjjjDA0dOlSvvPKKli5dqtbWVv3kJz+RJLW1tWncuHEBzxk5cqTvsaOOOsr2dVesWKHbbrstuYtH5vN+uNs1kUvh8eOQze8OeqT8/07sm7k4cgEAkiXhR7OXLFmiH/3oR2Hvefvtt/XpT3866Pojjzyib3zjG9q/f78KCgo0efJkjRs3Tg8++KDvnrfeeksnn3yy3nrrLZ144om2r9/d3a3u7m7fz11dXSorK+NoNuy5dPw47nlKHJsGkOWcHs1OeGZm8eLFmjNnTth7xo8fb3u9vLxcBw8e1Pbt23XCCSeopKRE7e3tAfd4fw5VZyNJBQUFKigoiG7hyF3xzFOKUdyBTAzjDwAgWyU8mCkuLlZxcXFMz21ublZeXp5GjBghSaqoqNC3v/1tffLJJzriiCMkSRs2bNAJJ5wQcosJSGcJmW4dqnPxrl3S9OnSwoXWVhKZGgA5wrUC4KamJtXW1uovf/mL/vnPf+rRRx/VjTfeqCuuuMIXqFx22WXq37+/rrrqKr355pt6/PHHtXLlSi1atMitZQMx6ehIUCDj8VgZmXBPqq11Z8YUALjEtXEGr7/+uq677jpt2bJF3d3dGjdunL7yla9o0aJFAVtEb7zxhubNm6c//elPGj58uBYsWKBvfvObUb0X4wzgpoQEMV5OxxL4vzEnlQBkKGYz+SGYgRueeEK65JLg69/5jvSDH8T4ouvWWdO9nUrVjCkASALXCoABJDgb4+9QPZlj/jOmUlzkDACp4nrTPCCbfP7z9oHMm28mIJCJR7JnTAGAi8jMAAmStGyMv/fei+15DJAEkMUIZoA4hQpiPB4pL9G5z2iDklTNmAIAF7HNBMQhXDYm4YGMFHn6tT8GSALIEQQzQAwMwz6eME2/bSWPxzpKvW6d9d3jie5N7J4fbkBmXwyQBJAj2GYCohAu4xJQGxPvuIFIzw81IHPuXOm445jVBCCn0GcGcMhxgW+ocQNOm9g5fT6DJgFkOZrm+SGYQTza2yW7uaaf+5zU1NTnosdjjRHwz5j4i9TELt7nA0AWcfr5Tc0MEIZh2AcypmkTyEhWpiRUIOJ9oreJnZ14nw8AOYhgBvB3qOj2yRs32m4rPfpohL4xTpvThbov3ucDQA6iABjwOlR0a+zaafuwow1Zp31gQt0X7/MBIAeRmQEkqa5OV03faxvItGuEzCfrnL1OpD4whiGVlYVuYhfv8wEgBxHMAB6PjOk1ekRfC3rIlKERel+6+urgPjHR9oFx0sQu3ucDQA4imEHmibcZnZ+zzpKMfsGBQa8MmfILJvbskZYvP/xzXZ116qiqSrrsMuv72LHWdW8fmDFjAl/UaRO7eJ8PADmGo9nILPE2o/MTsm+MQjwwbJh1TvuZZ1LTB4Y+MgByHH1m/BDMZIl4m9H1ub2vkEGMv9//Xpozhz4wAJAC9JlBdvF4rIyMXeztvbZwYdgtJ9O0D2T+s9qUOXSYs3U0NtIHBgDSDMEMMkOczeQMw36mkmlKv9tgWIFSItEHBgBShmAGmSHGZnIdHfbZmAcf7JPk+fa3rZqYULxHoisrna2DPjAAkDI0zUNmiKGZnOPBkJJV3/LQQ9L06aGfVFtrBTOlpVJLi/0LeWtm6AMDAClDZgaZIYpmcps22d+2ZYvDLr7h0AcGANIOwQwyg8MgwuiXr4qK4KebpnTCCWFe31tgHIphHC4wpg8MAKQVghlkjjBBxJ1X/EXG9OAg4qOPHGZjoi0wrqmRtm+XGhqktWut79u2EcgAgAuomUFmqamRpk0LaCZnVFVKvwq+NaotpVgKjPPznRcEAwCShmAGmedQEFFRIW3aFPxwTHUxTKsGgIxFMIOMZFfgW1Qk7d0b4wt6C4wz6ZQS4w4AQBI1M8gwgwbZBzKmGUcgI2XeKaVwgy4BIMcQzCAj9PZaMcWBA4HX589PwHFrr0w5peSdUdW3YLmlxbpOQAMgxzBoEmkvquZ3iZDO2zcej5WBYdAlgBzg9PObmhmkrT17pOHDg6+/9JJ03nlJfON0PqUUzRHydP0zAECCEcwgLaU0G5POmZi+YpxRBQDZjJoZpJW//tU+kGltTVIgk2mFtBwhB4AgBDNIG4YhnXpq8HXTlEpKkvCGmVhIG8WMKgDIFQQzcN1jj9l/Nn+ifjJLy5ITVHhnMdmle7zXvLOY0kmmHSEHgBQgmIGrDEOaNSvw2gS9K1OG+smTvCxJtLOY0kmmHCEHgBRJWjCzfPlyTZw4UUceeaSGDBlie8+OHTt04YUX6sgjj9SIESN088036+DBgwH3NDY26owzzlBBQYEmTJigNWvWJGvJSKEFC0I0v5Ohd3W834UkZUkSVUjr8UiNjdK6ddb3VGVyGHQJAD5JO83U09OjmTNnqqKiQj//+c+DHvd4PLrwwgtVUlKiV155Ra2trfrqV7+qI444QnfccYckadu2bbrwwgt1zTXX6NFHH1V9fb2+/vWva9SoUZoyZUqylo4kswtirtdKrdRC+yck6rix/6ml9nZnz2lvtwIVu1NOdXXWVpV/hqe01NoGSkVQkc5HyAEglcwkW716tVlUVBR0/bnnnjPz8vLMtrY237Wf/exnZmFhodnd3W2apmnecsst5sknnxzwvEsuucScMmVKVGvo7Ow0JZmdnZ3R/wGQMNOmmaYVmQR+mWvX2j/Q92vt2tjf/MknTbO0NPD18vLCv19+fuDPpaXW63hfzzCCn2MY1pf3PgBAzJx+frtWM9PU1KRTTjlFI0eO9F2bMmWKurq69Oabb/ruqa6uDnjelClT1NTUFPa1u7u71dXVFfAFl3g88tQ3yjCkZ54JfOixxw7tIiX7uHGoU0u9veGf13fLyFu/s359ZhYPA0CWci2YaWtrCwhkJPl+bmtrC3tPV1eXPvroo5CvvWLFChUVFfm+ysrKErx6OFJXp6mf2qh+1ZVBD5mmdMklh35I5nHjcKeWouV9jeuuy9ziYQDIQlEFM0uWLJFhGGG/tmzZkqy1OrZ06VJ1dnb6vnbu3On2knLO/kefkTG9Ri90VwZc36oJMo28wNNJyTxuHOnUUrRMU3r/fWf39k1FAQCSIqoC4MWLF2vOnDlh7xk/fryj1yopKdFrr70WcK39UFFmyaEOaSUlJb5r/vcUFhZq4MCBIV+7oKBABQUFjtaBxBs0yNSBA9MCrn1K+7Vfgw/9ZFjbMNOmHQ5QvMeN7Qpqa2tjL6h1s61/ba2VTeKEEQAkVVTBTHFxsYqLixPyxhUVFVq+fLnee+89jRgxQpK0YcMGFRYW6qSTTvLd89xzzwU8b8OGDaqoqEjIGpBY//qXNQlACsyuHNCROlJ+24KhTifV1FgBTiLnJCWrrf/w4dYkzEjbV32DNgBAwiWtZmbHjh1qbm7Wjh075PF41NzcrObmZu3fv1+SNHnyZJ100kn6yle+or/85S964YUX9J3vfEfz5s3zZVWuueYa/fOf/9Qtt9yiLVu26P7779cTTzyhG2+8MVnLRowMwxvIHDZd62XKCAxk/NllTbzHjWfNsr7HGwREqseJlrd+5/77ndXhUDsDAMmXrONUs2fPNiUFfTU0NPju2b59u3nBBReYAwcONIcPH24uXrzY/OSTTwJep6GhwTz99NPN/v37m+PHjzdXr14d9Vo4mp08f/iD/anmXidHrf3+XUgq7zFqu6PUdker7f7Z7tj1woXJP1IOADnM6ee3YZpJmUWcVrq6ulRUVKTOzk4VFha6vZysYZfsWL5c+tY3PVaapqXFPnthGFa2ZNu21G2/2DW4GzbM+r5nz+FrZWVWrYsUfL/3MW8NTGOjNWU7koYGmtsBQAycfn4TzCBqa9ZIV14ZfD3g3yRvb5e+D3gjIDdmCPl3APbW40iha3Ts7vcPvjxpGLQBQBYhmPFDMJM4dtmYp5+2alyD2GVD+mY3Ml06Bm0AkCUIZvwQzMRv8WLpJz8Jvh7x355I2Y1skAtBGwC4gGDGD8FM7A4elI44Ivj6X/4inXpq6teTtnIhaAOAFHP6+Z20qdnIfOeeK/3xj8HXsz/8jQETrAHANQQzCLJ3r3TUUcHX29ulQ/0NAQBIGwQzCGBX4HvccdLf/576tQAA4IRrU7ORXrZutQ9kPv6YQAYAkN4IZiDDsLIv/r76Vas2JuHzOj0eq9ncunXWd48nwW8AAMg1bDPlsL/9TTrllODrvb2JG2UUwO4Ic2mptHIlR5gBADEjM5OjDCM4kLnnHisbk7RAZsaMwEBGsrrnzphhPQ4AQAwIZnLMhg32wYppSgsXJulNPR4rI2N3ptt7beFCtpwAADEhmMkR3ozL5MmB1//85xT0jdm4MTgj4880pZ07rfsAAIgSwUwOePhhKa/P/9JjxlgxxOmnp2ABra2JvU+ikBgA4EMBcBYLNYpg1y4rmEmZUaMSex+FxAAAP2RmstTNNwcHMv/1X1Y2JqWBjGTNKSotDV1ZbBjWYMZJkyK/FoXEAIA+yMxkmX37JLtZXPv2SYMGpX49kqy5RStXWsGGYQQW6XgDnNrayIMZIxUSG4ZVSDxtGkMeASCHkJnJIl/8YnAgc8st1ue8a4GMV02NtH59cFqotNS67mR7iEJiAIANMjNZYNcua5emr4MH0yxBUVNjZU02brSKfUeNsraWnC4yGYXEAICMRzCT4UaNktraAq89/LD09a+7s56I8vOlysrYnpvoQmIAQFYgmMlQf/6zdMYZwdeT3jPGTd5C4pYW+z+oYViPOykkBgBkDWpmMpBhBAcyGzZkeSAjHS4kloJPRkVTSAwAyCoEMxnkt78NPYqgujr163FFIgqJAQBZhW2mDGCawR18JWvq9cknp349rou3kBgAkFUIZtLcffdJCxYEXjvuOOnvf3dnPWkjnkJiAEBWIZhJU598IvXvH3y9rU0aOTL16wEAIF1RM5OGFiwIDmRmzrS2mwhkAAAIRGYmjXR2SkOGBF8/cEA68siULwcAgIxAZiZNVFYGBzLLllnZGAIZAABCIzPjsu3bpXHjgq97PPYnmAAAQCA+Ll1UWBgcyPzyl6GPYgMAgGBkZlzw2mtSeXnw9azv4AsAQBLw3/8pZhjBgcxLLxHIAAAQK4KZFKmrCz2K4LzzUr8eAACyBdtMSRaq/mXLFumEE1K/HgAAsg2ZmSS6++7gQOb0060Ah0AGAIDESFows3z5ck2cOFFHHnmkhth1gpNkGEbQ12OPPRZwT2Njo8444wwVFBRowoQJWrNmTbKWnDDd3daW0k03BV5//33pz392Z00AAGSrpAUzPT09mjlzpq699tqw961evVqtra2+r4svvtj32LZt23ThhReqqqpKzc3NWrhwob7+9a/rhRdeSNay4zZ3rjRgQOC1r37VysYMH+7OmgAAyGZJq5m57bbbJCliJmXIkCEqKSmxfeyBBx7QuHHjdPfdd0uSTjzxRP3hD3/QPffcoylTpiR0vfHq6JCGDQu+/tFHwcENAABIHNdrZubNm6fhw4frnHPO0SOPPCLT74xyU1OTqqurA+6fMmWKmpqawr5md3e3urq6Ar6Safbs4EDmjjusbAyBDAAAyeXqaabvf//7Ov/883XkkUfqd7/7na677jrt379f119/vSSpra1NI/uMiR45cqS6urr00UcfaeDAgbavu2LFCl9mKJlCZWMYRQAAQOpE9ZG7ZMkS26Jd/68tW7Y4fr3vfve7+vznP6/Pfvaz+uY3v6lbbrlFd955Z9R/iL6WLl2qzs5O39fOnTvjfk0711wT+PPjjzOKAACAVIsqM7N48WLNmTMn7D3jx4+PeTHl5eX6wQ9+oO7ubhUUFKikpETt7e0B97S3t6uwsDBkVkaSCgoKVFBQEPM6nPrCF6Rf/1q6+mrpwQeT/nYAAMBGVMFMcXGxiouLk7UWNTc366ijjvIFIhUVFXruuecC7tmwYYMqKiqStoZofOMb1ldG83ikjRul1lZp1Chp0iQpP9/tVQEA4FjSamZ27Nihjo4O7dixQx6PR83NzZKkCRMmaNCgQXr22WfV3t6uz33ucxowYIA2bNigO+64Qzf5NWe55pprdN999+mWW27R1772Nb344ot64okn9Nvf/jZZy84tdXXSDTdIu3YdvlZaKq1cKdXUuLcuAACiYJhmckYczpkzR7/4xS+Crjc0NKiyslLPP/+8li5dqq1bt8o0TU2YMEHXXnut5s6dqzy/opPGxkbdeOONeuutt1RaWqrvfve7Ebe6+urq6lJRUZE6OztVWFgY7x8tUKZmNurqpBkzgidcegdIrV9PQAMAcJXTz++kBTPpJGnBTKZmNjweaezYwHX7Mwzrz7FtW2YEZgCArOT085tzN7HyZjb6BgQtLdb1ujp31uXExo2hAxnJytbs3GndBwBAmiOYiYXHY2Vk7JJa3msLF1r3paPW1sTeBwCAiwhmYpHpmY1RoxJ7HwAALiKYiUWmZzYmTbJqYrzFvn0ZhlRWZt0HAECaI5iJRaZnNvLzrSJlKTig8f5cW0vxLwAgIxDMxCIbMhs1Ndbx6zFjAq+XlnIsGwCQUVwdNJmxvJmNGTOswMW/EDiTMhs1NdK0aZnZJwcAgEMIZmLlzWzY9Zmprc2czEZ+vlRZ6fYqAACIGcFMPMhsAADgOoKZeJHZAADAVRQAAwCAjEYwAwAAMhrBDAAAyGgEMwAAIKMRzAAAgIxGMAMAADIawQwAAMho9JmJlcdDszwAANIAwUws6ursxxisXJk5YwwAAMgSbDNFq67OGjDpH8hIUkuLdb2uzp11AQCQowhmouHxWBkZ/ynZXt5rCxda9wEAgJQgmInGxo3BGRl/pint3GndBwAAUoJgJhqtrYm9DwAAxI1gJhqjRiX2PgAAEDeCmWhMmmSdWjIM+8cNQyors+4DAAApQTATjfx86/i1FBzQeH+uraXfDAAAKUQwE62aGmn9emnMmMDrpaXWdfrMAACQUjTNi0VNjTRtGh2AAQBIAwQzscrPlyor3V4FAAA5j20mAACQ0QhmAABARiOYAQAAGY1gBgAAZDSCGQAAkNEIZgAAQEYjmAEAABmNYAYAAGQ0ghkAAJDRcqIDsGmakqSuri6XVwIAAJzyfm57P8dDyYlgZt++fZKksrIyl1cCAACitW/fPhUVFYV83DAjhTtZoLe3V7t379bgwYNlGIbby0marq4ulZWVaefOnSosLHR7OVmP33fq8TtPPX7nqcfv/DDTNLVv3z6NHj1aeXmhK2NyIjOTl5en0tJSt5eRMoWFhTn/f4BU4vedevzOU4/feerxO7eEy8h4UQAMAAAyGsEMAADIaAQzWaSgoEDLli1TQUGB20vJCfy+U4/feerxO089fufRy4kCYAAAkL3IzAAAgIxGMAMAADIawQwAAMhoBDMAACCjEcxkoe3bt+uqq67SuHHjNHDgQB177LFatmyZenp63F5aVlu+fLkmTpyoI488UkOGDHF7OVlp1apVGjt2rAYMGKDy8nK99tprbi8pa7388su66KKLNHr0aBmGoaefftrtJWW9FStW6Oyzz9bgwYM1YsQIXXzxxXrnnXfcXlZGIJjJQlu2bFFvb68efPBBvfnmm7rnnnv0wAMP6Fvf+pbbS8tqPT09mjlzpq699lq3l5KVHn/8cS1atEjLli3T66+/rtNOO01TpkzRe++95/bSstKBAwd02mmnadWqVW4vJWe89NJLmjdvnjZt2qQNGzbok08+0eTJk3XgwAG3l5b2OJqdI+6880797Gc/0z//+U+3l5L11qxZo4ULF2rv3r1uLyWrlJeX6+yzz9Z9990nyZq5VlZWpgULFmjJkiUury67GYahp556ShdffLHbS8kp77//vkaMGKGXXnpJ5513ntvLSWtkZnJEZ2enhg4d6vYygJj09PRo8+bNqq6u9l3Ly8tTdXW1mpqaXFwZkDydnZ2SxN/dDhDM5ICtW7fq3nvv1Te+8Q23lwLE5IMPPpDH49HIkSMDro8cOVJtbW0urQpInt7eXi1cuFCf//zn9ZnPfMbt5aQ9gpkMsmTJEhmGEfZry5YtAc9paWnR1KlTNXPmTM2dO9ellWeuWH7nABCvefPm6W9/+5see+wxt5eSEfq5vQA4t3jxYs2ZMyfsPePHj/f98+7du1VVVaWJEyfqoYceSvLqslO0v3Mkx/Dhw5Wfn6/29vaA6+3t7SopKXFpVUByzJ8/X7/5zW/08ssvq7S01O3lZASCmQxSXFys4uJiR/e2tLSoqqpKZ555plavXq28PJJwsYjmd47k6d+/v84880zV19f7ilB7e3tVX1+v+fPnu7s4IEFM09SCBQv01FNPqbGxUePGjXN7SRmDYCYLtbS0qLKyUsccc4zuuusuvf/++77H+K/Y5NmxY4c6Ojq0Y8cOeTweNTc3S5ImTJigQYMGubu4LLBo0SLNnj1bZ511ls455xzV1tbqwIEDuvLKK91eWlbav3+/tm7d6vt527Ztam5u1tChQ3X00Ue7uLLsNW/ePK1du1bPPPOMBg8e7KsHKyoq0sCBA11eXZozkXVWr15tSrL9QvLMnj3b9nfe0NDg9tKyxr333mseffTRZv/+/c1zzjnH3LRpk9tLyloNDQ22/z7Pnj3b7aVlrVB/b69evdrtpaU9+swAAICMRiEFAADIaAQzAAAgoxHMAACAjEYwAwAAMhrBDAAAyGgEMwAAIKMRzAAAgIxGMAMAADIawQwAAMhoBDMAACCjEcwAAICMRjADAAAy2v8HhHVnSGzNDN8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "Ovay73W01BIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "mEAWc99U1JyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "O9rwhyet1JYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW1boQAm-tEv",
        "outputId": "a8459ff6-11b2-4eba-f323-eedde59954ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer() #PyTorch testing dataset\n",
        "X, y = bc.data, bc.target\n",
        "print(X[:5],y[:50]) #See from X that it has multiple factors, depending on what value each factor is, it would result it either 0\n",
        "                    # for negative, or 1 for positive\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)#Function that allows you to split data into test or train\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler() #z = (x - u) / s; z is the scaled value, x is the original value, u is the mean of the feature, s is the standard deviation of the feature\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x)) #The sigmoid function specifically \"squashes\" the logits into a range between 0 and 1\n",
        "        # 1/(1 + e^{-x})\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss() #Binary cross-entropy loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hViTiIcGLbsU",
        "outputId": "ad14aaa2-e168-484a-8257-36a70718de8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            "  1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            "  6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            "  1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            "  4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 1.326e+03 8.474e-02 7.864e-02 8.690e-02\n",
            "  7.017e-02 1.812e-01 5.667e-02 5.435e-01 7.339e-01 3.398e+00 7.408e+01\n",
            "  5.225e-03 1.308e-02 1.860e-02 1.340e-02 1.389e-02 3.532e-03 2.499e+01\n",
            "  2.341e+01 1.588e+02 1.956e+03 1.238e-01 1.866e-01 2.416e-01 1.860e-01\n",
            "  2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 1.203e+03 1.096e-01 1.599e-01 1.974e-01\n",
            "  1.279e-01 2.069e-01 5.999e-02 7.456e-01 7.869e-01 4.585e+00 9.403e+01\n",
            "  6.150e-03 4.006e-02 3.832e-02 2.058e-02 2.250e-02 4.571e-03 2.357e+01\n",
            "  2.553e+01 1.525e+02 1.709e+03 1.444e-01 4.245e-01 4.504e-01 2.430e-01\n",
            "  3.613e-01 8.758e-02]\n",
            " [1.142e+01 2.038e+01 7.758e+01 3.861e+02 1.425e-01 2.839e-01 2.414e-01\n",
            "  1.052e-01 2.597e-01 9.744e-02 4.956e-01 1.156e+00 3.445e+00 2.723e+01\n",
            "  9.110e-03 7.458e-02 5.661e-02 1.867e-02 5.963e-02 9.208e-03 1.491e+01\n",
            "  2.650e+01 9.887e+01 5.677e+02 2.098e-01 8.663e-01 6.869e-01 2.575e-01\n",
            "  6.638e-01 1.730e-01]\n",
            " [2.029e+01 1.434e+01 1.351e+02 1.297e+03 1.003e-01 1.328e-01 1.980e-01\n",
            "  1.043e-01 1.809e-01 5.883e-02 7.572e-01 7.813e-01 5.438e+00 9.444e+01\n",
            "  1.149e-02 2.461e-02 5.688e-02 1.885e-02 1.756e-02 5.115e-03 2.254e+01\n",
            "  1.667e+01 1.522e+02 1.575e+03 1.374e-01 2.050e-01 4.000e-01 1.625e-01\n",
            "  2.364e-01 7.678e-02]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
            "epoch: 10, loss = 0.5903\n",
            "epoch: 20, loss = 0.4808\n",
            "epoch: 30, loss = 0.4124\n",
            "epoch: 40, loss = 0.3657\n",
            "epoch: 50, loss = 0.3315\n",
            "epoch: 60, loss = 0.3053\n",
            "epoch: 70, loss = 0.2844\n",
            "epoch: 80, loss = 0.2674\n",
            "epoch: 90, loss = 0.2531\n",
            "epoch: 100, loss = 0.2409\n",
            "accuracy: 0.8684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Softmax and Cross-Entropy"
      ],
      "metadata": {
        "id": "iX7dCF379pwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "H6tyPUkyGTkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QN7qpxOmGW4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax applies the exponential function to each element, and normalizes\n",
        "# by dividing by the sum of all these exponentials\n",
        "# -> squashes the output to be between 0 and 1 = probability\n",
        "# sum of all probabilities is 1\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "# Cross entropy\n",
        "# Cross-entropy loss, or log loss, measures the performance of a classification model\n",
        "# whose output is a probability value between 0 and 1.\n",
        "# -> loss increases as the predicted probability diverges from the actual label\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
        "# nn.LogSoftmax + nn.NLLLoss\n",
        "# NLLLoss = negative log likelihood loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# loss(input, target)\n",
        "\n",
        "# target is of size nSamples = 1\n",
        "# each element has class label: 0, 1, or 2\n",
        "# Y (=target) contains class labels, not one-hot\n",
        "Y = torch.tensor([0]) #[0] means we look at the first value of Y_pred, [1] means we look at the second, [2] we look at the third\n",
        "\n",
        "# input is of size nSamples x nClasses = 1 x 3\n",
        "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "# allows batch loss for multiple samples\n",
        "\n",
        "# target is of size nBatch = 3\n",
        "# each element has class label: 0, 1, or 2\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# input is of size nBatch x nClasses = 3 x 3\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9], # predict class 2\n",
        "    [1.2, 0.1, 0.3], # predict class 0\n",
        "    [0.3, 2.2, 0.2]]) # predict class 1\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL_R_LNhGQ_G",
        "outputId": "f520a431-e49c-482d-899b-b2b74622b5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "PyTorch Loss1: 0.4170\n",
            "PyTorch Loss2: 1.8406\n",
            "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n",
            "Batch Loss1:  0.2834\n",
            "Batch Loss2: 1.6418\n",
            "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Activation Functions"
      ],
      "metadata": {
        "id": "jrWzKqgzJfjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "mLIBH91uOZZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = torch.relu(x)\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srN9aV49PYe0",
        "outputId": "2bed1c34-ce3c-4f04-be03-bb47312ee8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output = w*x + b\n",
        "# output = activation_function(output)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size) #Input size and hidden size\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1) #Hidden size and output size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x) #valuess go in, transform into w.transpose * x_vector\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjXQegZ6OdL3",
        "outputId": "f9baea8c-b795-458b-ac89-f02e261e169a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feed Forward Neural Network"
      ],
      "metadata": {
        "id": "c4RU3ODDRTzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in list(globals().keys()):\n",
        "    if not name.startswith(\"_\"):\n",
        "        del globals()[name]"
      ],
      "metadata": {
        "id": "z-2Oo8quRXs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Gpqe0bt7RXYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_EHbS81_RSDs",
        "outputId": "c20cc32a-793e-4950-e3ad-2309ea3b7911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 41.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.22MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.3010\n",
            "Epoch [1/2], Step [200/600], Loss: 0.1928\n",
            "Epoch [1/2], Step [300/600], Loss: 0.1194\n",
            "Epoch [1/2], Step [400/600], Loss: 0.1799\n",
            "Epoch [1/2], Step [500/600], Loss: 0.1252\n",
            "Epoch [1/2], Step [600/600], Loss: 0.2116\n",
            "Epoch [2/2], Step [100/600], Loss: 0.1069\n",
            "Epoch [2/2], Step [200/600], Loss: 0.0706\n",
            "Epoch [2/2], Step [300/600], Loss: 0.1417\n",
            "Epoch [2/2], Step [400/600], Loss: 0.1363\n",
            "Epoch [2/2], Step [500/600], Loss: 0.1689\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0800\n",
            "Accuracy of the network on the 10000 test images: 97.36 %\n"
          ]
        }
      ]
    }
  ]
}